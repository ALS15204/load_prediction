{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f61320cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ronin/Cloud_Drive/AI_works/Projects/Amperon/notebook', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/ronin/Cloud_Drive/AI_works/Projects/Amperon/venv/lib/python3.8/site-packages', '/home/ronin/Cloud_Drive/AI_works/Projects/Amperon']\n"
     ]
    }
   ],
   "source": [
    "# Set up project path\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "notebook_path = sys.path[0]\n",
    "sys.path.append(str(Path(notebook_path).parent))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca3cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "from load_prediction import DATA_DIR\n",
    "\n",
    "# Define constants\n",
    "N_STATION = 28\n",
    "N_EXP = 1000\n",
    "PREDICTION_OUTPUT_DIR = DATA_DIR / \"predictions\"\n",
    "LOAD_PREDICTION_FILE_NAME = \"load_predict\"\n",
    "\n",
    "# Load data\n",
    "hist_data = pandas.read_csv(DATA_DIR / \"load_hist_data.csv\")\n",
    "weather_data = pandas.read_csv(DATA_DIR / \"weather_data.csv\")\n",
    "prediction = pandas.read_csv(DATA_DIR / \"probability_estimates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ce858ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add temperature information to hist_data to prepare features\n",
    "for station_id in range(1, N_STATION + 1):\n",
    "    temperature = weather_data.query(f\"`Station ID` == {station_id}\")[\"Temperature\"].values\n",
    "    hist_data.insert(len(hist_data.columns), f\"Station_{station_id}_T\", temperature, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151753c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "X_all_T = hist_data.drop([\"Date\", \"Load\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9017391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_prediction.utils.data_manipulators import Date\n",
    "\n",
    "# Compute days into a year for a given date and add it as a feature\n",
    "dates = list(map(Date, hist_data[\"Date\"]))\n",
    "X_all_T.insert(1, \"Days_of_Year\", [d.days_in_year for d in dates], True)\n",
    "X_all_T.insert(2, \"Year\", [d.year for d in dates], True)\n",
    "X_all_T.insert(3, \"Is_Holiday\", [d.is_holiday for d in dates], True)\n",
    "X_all_T.insert(4, \"Weekday\", [d.weekday for d in dates], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d976e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average temperature to be used as a feature as well as a training data\n",
    "Temp = pandas.DataFrame()\n",
    "temperatures = X_all_T.drop([\"Days_of_Year\", \"Hour\", \"Year\"], axis=1)\n",
    "Temp.insert(0, \"Temperature\", temperatures.values.mean(axis=1), True)\n",
    "\n",
    "Y = hist_data[\"Load\"]\n",
    "\n",
    "# Prepare features for training a load prediction model\n",
    "X_avg_T = X_all_T[[\"Days_of_Year\", \"Year\", \"Is_Holiday\", \"Weekday\", \"Hour\"]]\n",
    "X_avg_T.insert(len(X_avg_T.columns), \"Temperature\", temperatures.values.mean(axis=1), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58030d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input for prediction\n",
    "prediction_dates = list(map(Date, prediction[\"Date\"]))\n",
    "prediction.insert(1, \"Days_of_Year\", [d.days_in_year for d in prediction_dates], True)\n",
    "prediction.insert(2, \"Year\", [d.year for d in prediction_dates], True)\n",
    "prediction.insert(3, \"Is_Holiday\", [d.is_holiday for d in prediction_dates], True)\n",
    "prediction.insert(4, \"Weekday\", [d.weekday for d in prediction_dates], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "355b1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Build prediction process\n",
    "def process(n_random):\n",
    "    X_2_train, X_2_test, Y_train, Y_test = train_test_split(X_avg_T, Y, test_size=0.2, random_state=n_random)\n",
    "    mdl_rf_2 = RandomForestRegressor()\n",
    "    mdl_rf_2.fit(X_2_train, Y_train)\n",
    "\n",
    "    X_T = X_2_train[[\"Days_of_Year\", \"Year\", \"Hour\"]]\n",
    "    mdl_rf_T = RandomForestRegressor()\n",
    "    mdl_rf_T.fit(X_T, X_2_train[\"Temperature\"])\n",
    "\n",
    "    X_pred = prediction.drop([\"Date\", \"Daily Peak Probability\"], axis=1)\n",
    "    X_pred.insert(len(X_pred.columns), \"Temperature\", mdl_rf_T.predict(X_pred[[\"Days_of_Year\", \"Year\", \"Hour\"]]), True)\n",
    "\n",
    "    answers = X_pred.copy()\n",
    "    answers.insert(0, \"Date\", prediction[\"Date\"], True)\n",
    "    answers.insert(len(answers.columns), \"Load\", mdl_rf_2.predict(X_pred), True)\n",
    "    answers = answers.drop([\"Days_of_Year\"], axis=1)\n",
    "    answers.to_csv(PREDICTION_OUTPUT_DIR / f\"{LOAD_PREDICTION_FILE_NAME}_{n_random}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb1eb85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction complete\n"
     ]
    }
   ],
   "source": [
    "# 1000 Predictions in parallel\n",
    "from load_prediction.utils.multi_processing import pmap\n",
    "n_tries = [n for n in range(N_EXP)]\n",
    "pmap(process, n_tries, num_workers=8)\n",
    "print(\"Prediction complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3b0bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_prediction import DATA_DIR\n",
    "\n",
    "PREDICTIONS_DIR = DATA_DIR / \"predictions\"\n",
    "PROB_INPUT = PREDICTIONS_DIR.parent / \"probability_estimates.csv\"\n",
    "PROB_OUTPUT = PREDICTIONS_DIR.parent / \"output/probability_estimates.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "394ba83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data compilation complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from load_prediction.scripts.prediction import N_EXP\n",
    "from load_prediction.utils.data_manipulators import PredictionDF\n",
    "\n",
    "vote_df = pandas.read_csv(PROB_INPUT)\n",
    "vote_df[\"Vote\"] = np.zeros(len(vote_df), dtype=int)\n",
    "\n",
    "all_dates = set(vote_df[\"Date\"].values)\n",
    "\n",
    "for file in PREDICTIONS_DIR.iterdir():\n",
    "    predict_df = PredictionDF(file)\n",
    "    date_to_peak = {date: predict_df.peak_hour_on_date(date) for date in all_dates}\n",
    "    for date, hour in date_to_peak.items():\n",
    "        row_idx = vote_df.query(f\"Date == '{date}' & Hour == {hour}\")[\"Vote\"].index\n",
    "        vote_df.loc[row_idx, \"Vote\"] += 1\n",
    "vote_df.to_csv(PREDICTIONS_DIR.parent / \"output/vote_out.csv\")\n",
    "\n",
    "vote_df[\"Daily Peak Probability\"] = vote_df[\"Vote\"] / N_EXP\n",
    "vote_df = vote_df.drop([\"Vote\"], axis=1)\n",
    "vote_df.to_csv(PROB_OUTPUT)\n",
    "print(\"Data compilation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b87a4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
